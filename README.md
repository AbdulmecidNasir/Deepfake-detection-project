<div align="center">
<!-- BURAYA BANNER FOTOÄRAFINIZI EKLEYÄ°N. Ã–rnek: -->
<!-- <img src="https://user-images.githubusercontent.com/username/repo/banner.png" alt="Proje Banner'Ä±" width="900"/> -->
Derin EvriÅŸimli Sinir AÄŸlarÄ± ile Deepfake Video Tespiti
FET312 - Derin Ã–ÄŸrenme Dersi / 2025-2026 GÃ¼z DÃ¶nemi Vize Projesi
Ekip AdÄ±: Detectify
</div>
Bu proje, Ä°stanbul TopkapÄ± Ãœniversitesi FET312 - Derin Ã–ÄŸrenme dersi kapsamÄ±nda, Deepfake teknolojisiyle manipÃ¼le edilmiÅŸ videolarÄ± tespit etmek iÃ§in temel (baseline) KonvolÃ¼syonel Sinir AÄŸÄ± (CNN) modellerinin geliÅŸtirilmesi ve performans analizini konu almaktadÄ±r.
ğŸ“ Ä°Ã§indekiler
Problem TanÄ±mÄ± ve Hedefler
Veri Seti
Genel Metodoloji
Ekip KatkÄ±larÄ± ve GeliÅŸtirilen Modeller
Performans SonuÃ§larÄ± ve Analiz
Gelecek Ã‡alÄ±ÅŸmalar: Final AÅŸamasÄ± PlanÄ±
KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler
Kurulum ve Ã‡alÄ±ÅŸtÄ±rma
ğŸ¯ Problem TanÄ±mÄ± ve Hedefler
GÃ¼nÃ¼mÃ¼zde "Deepfake" teknolojisi, yapay zeka ile gerÃ§eÄŸi manipÃ¼le etme konusunda ciddi bir tehdit oluÅŸturmaktadÄ±r. Bu projenin temel bilimsel sorusu, insan gÃ¶zÃ¼yle ayÄ±rt edilmesi zorlaÅŸan gÃ¶rsel manipÃ¼lasyonlarÄ±n, piksel dÃ¼zeyindeki tutarsÄ±zlÄ±klar kullanÄ±larak otomatik olarak tespit edilip edilemeyeceÄŸidir.
Proje, Ä°kili SÄ±nÄ±flandÄ±rma (Binary Classification) problemi olarak ele alÄ±nmÄ±ÅŸ ve bir videonun "GerÃ§ek (Real)" mi yoksa "Sahte (Fake)" mi olduÄŸunu belirlemeyi amaÃ§lamaktadÄ±r.
Vize AÅŸamasÄ± (Baseline): SÄ±fÄ±rdan tasarlanan sÄ±ÄŸ (shallow) CNN modelleri ile rassal tahminin (%50) Ã¼zerine Ã§Ä±karak, modelin manipÃ¼lasyon izlerini Ã¶ÄŸrenmeye baÅŸladÄ±ÄŸÄ±nÄ± kanÄ±tlamak. Hedef, %60-65 arasÄ± doÄŸruluk ve 0.50 Ã¼zeri F1 Skoru'na ulaÅŸmaktÄ±r.
Final AÅŸamasÄ± (Advanced): Transfer Ã–ÄŸrenme (Transfer Learning) tekniÄŸi kullanarak literatÃ¼rdeki standartlara yaklaÅŸmak ve %85 Ã¼zeri doÄŸruluk hedeflemek.
ğŸ“Š Veri Seti
Veri KÃ¼mesi: FaceForensics++ (FF++)
Kaynak: Kaggle ve TU Munich
Detaylar: C23 (orta seviye) sÄ±kÄ±ÅŸtÄ±rma uygulanmÄ±ÅŸ videolardan oluÅŸmaktadÄ±r.
EÄŸitim Seti: Toplam 500 video (250 GerÃ§ek, 250 Sahte). Sahte videolar, farklÄ± manipÃ¼lasyon tekniklerinden (Deepfakes, Face2Face, FaceSwap vb.) 50'ÅŸer adet iÃ§ermektedir.
Test Seti: EÄŸitimde hiÃ§ kullanÄ±lmamÄ±ÅŸ 50 video (25 GerÃ§ek, 25 Sahte) iÃ§eren bir "Hold-out Test Seti" oluÅŸturulmuÅŸtur.
âš™ï¸ Genel Metodoloji
TÃ¼m ekip Ã¼yeleri tarafÄ±ndan ortak bir veri iÅŸleme boru hattÄ± (pipeline) izlenmiÅŸtir:
Video Okuma: EÄŸitim ve test setlerindeki .mp4 formatÄ±ndaki videolar okunur.
Karelere AyÄ±rma (Frame Extraction): Her videodan saniyede belirli aralÄ±klarla kareler Ã§Ä±karÄ±lÄ±r.
YÃ¼z Tespiti ve KÄ±rpma: MTCNN veya face_recognition kÃ¼tÃ¼phaneleri kullanÄ±larak her karedeki insan yÃ¼zleri tespit edilir ve kÄ±rpÄ±lÄ±r.
Yeniden BoyutlandÄ±rma: KÄ±rpÄ±lan yÃ¼z gÃ¶rÃ¼ntÃ¼leri, her Ã¼yenin kendi model mimarisine uygun olarak yeniden boyutlandÄ±rÄ±lÄ±r.
Model EÄŸitimi: HazÄ±rlanan yÃ¼z gÃ¶rÃ¼ntÃ¼leri ile her Ã¼yenin kendi tasarladÄ±ÄŸÄ± CNN modeli eÄŸitilir.
DeÄŸerlendirme: Modelin performansÄ±, test setindeki videolar Ã¼zerinde karelerin Ã§oÄŸunluk oyu (Majority Voting) yÃ¶ntemiyle Ã¶lÃ§Ã¼lÃ¼r.
ğŸ‘¥ Ekip KatkÄ±larÄ± ve GeliÅŸtirilen Modeller
Ekibimiz, farklÄ± temel model yaklaÅŸÄ±mlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak amacÄ±yla aÅŸaÄŸÄ±daki ÅŸekilde iÅŸ bÃ¶lÃ¼mÃ¼ yapmÄ±ÅŸtÄ±r:
GeliÅŸtirici	Ã–ÄŸrenci No	GeliÅŸtirilen Model	Ã–ne Ã‡Ä±kan MimarÃ® Ã–zellikler
Khaiitmurod Khabibullayev	22040101116	SimpleCNN	3 evriÅŸim katmanlÄ± temel bir yapÄ±. AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi engellemek iÃ§in %50 Dropout katmanÄ± kullanÄ±lmÄ±ÅŸtÄ±r. Girdi boyutu 224x224 pikseldir.
Muhammed Ali CÃ¼re	23040101006	BatchNormCNN	4 evriÅŸim katmanÄ± ile daha derin bir Ã¶zellik Ã§Ä±karÄ±mÄ± hedeflenmiÅŸtir. EÄŸitimi stabilize etmek iÃ§in her evriÅŸim katmanÄ±ndan sonra Batch Normalization ve "Ã¶lÃ¼ nÃ¶ron" problemini Ã§Ã¶zmek iÃ§in LeakyReLU aktivasyon fonksiyonu eklenmiÅŸtir. Girdi boyutu 224x224 pikseldir.
Abdumajid Abdulkhaev	22040101002	RescaledCNN	Ä°ÅŸlem yÃ¼kÃ¼nÃ¼ azaltmak amacÄ±yla girdi boyutu 128x128 piksele optimize edilmiÅŸtir. Modelin giriÅŸine piksel deÄŸerlerini aralÄ±ÄŸÄ±na normalize eden yerleÅŸik bir Rescaling katmanÄ± eklenmiÅŸtir. Daha az parametre ile Ã¶ÄŸrenmesi hedeflenmiÅŸtir.
ğŸ“ˆ Performans SonuÃ§larÄ± ve Analiz
TÃ¼m modeller, 50 videoluk (25 GerÃ§ek, 25 Sahte) "Hold-out Test Seti" Ã¼zerinde deÄŸerlendirilmiÅŸtir.
Performans KarÅŸÄ±laÅŸtÄ±rma Tablosu
Model GeliÅŸtiricisi	Model Mimarisi	DoÄŸruluk (Accuracy)	Hassasiyet (Precision-Fake)	DuyarlÄ±lÄ±k (Recall-Fake)	F1 Skoru
Muhammed Ali CÃ¼re	BatchNormCNN	%62.00	0.80	0.32	0.46
Khaiitmurod Khabibullayev	SimpleCNN	%58.00	0.83	0.20	0.32
Abdumajid Abdulkhaev	RescaledCNN	%50.00	0.50	1.00	0.67
SonuÃ§larÄ±n YorumlanmasÄ±
En Ä°yi BaÅŸarÄ± (BatchNormCNN): Muhammed Ali'nin geliÅŸtirdiÄŸi model, %62 doÄŸruluk oranÄ±yla en iyi genel performansÄ± sergilemiÅŸtir. Batch Normalization katmanlarÄ±nÄ±n, modelin veri setindeki gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± daha direnÃ§li olmasÄ±nÄ± saÄŸlayarak daha iyi genelleme yapmasÄ±na yardÄ±mcÄ± olduÄŸu dÃ¼ÅŸÃ¼nÃ¼lmektedir.
YÃ¼ksek Hassasiyet, DÃ¼ÅŸÃ¼k DuyarlÄ±lÄ±k (SimpleCNN): Khaiitmurod'un modeli, %83 gibi Ã§ok yÃ¼ksek bir Precision deÄŸerine ulaÅŸmÄ±ÅŸtÄ±r. Bu, modelin bir videoya "Sahte" dediÄŸinde bÃ¼yÃ¼k olasÄ±lÄ±kla doÄŸru tahminde bulunduÄŸunu, ancak emin olamadÄ±ÄŸÄ± birÃ§ok sahte videoyu "GerÃ§ek" olarak etiketleyerek "muhafazakar" davrandÄ±ÄŸÄ±nÄ± gÃ¶stermektedir (DÃ¼ÅŸÃ¼k Recall: 0.20).
Model SapmasÄ± / Bias Problemi (RescaledCNN): Abdumajid'in modeli, tÃ¼m sahte videolarÄ± doÄŸru tahmin etmiÅŸ (Recall: 1.00) ancak tÃ¼m gerÃ§ek videolarÄ± da sahte olarak etiketlemiÅŸtir. Bu durum, modelin ayÄ±rt edici Ã¶zellikleri Ã¶ÄŸrenmekte zorlandÄ±ÄŸÄ±nÄ± ve tÃ¼m girdileri "Sahte" olarak tahmin etme eÄŸilimine (Mode Collapse) girdiÄŸini gÃ¶stermektedir. Bu, basit CNN mimarilerinin karmaÅŸÄ±k deepfake manipÃ¼lasyonlarÄ±nÄ± Ã¶ÄŸrenmedeki zorluÄŸunu kanÄ±tlamaktadÄ±r.
ğŸš€ Gelecek Ã‡alÄ±ÅŸmalar: Final AÅŸamasÄ± PlanÄ±
Vize aÅŸamasÄ±nda elde edilen temel model sonuÃ§larÄ±, basit ve sÄ±ÄŸ CNN yapÄ±larÄ±nÄ±n bu problemde yetersiz kaldÄ±ÄŸÄ±nÄ± gÃ¶stermiÅŸtir. Final projesinde, modelleri daha derinleÅŸtirmek ve Ã¶nceden eÄŸitilmiÅŸ (pre-trained) aÄŸÄ±rlÄ±klarÄ± kullanmak (Transfer Learning) zorunlu hale gelmiÅŸtir.
GeliÅŸtirici	Planlanan GeliÅŸmiÅŸ Mimari	SeÃ§im Nedeni
Khaiitmurod Khabibullayev	InceptionV3	FarklÄ± boyutlardaki filtreleri paralel kullanarak gÃ¶rÃ¼ntÃ¼deki hem ince hem de kaba detaylarÄ± aynÄ± anda yakalayabilme yeteneÄŸi.
Abdumajid Abdulkhaev	ResNet50	Derin aÄŸlardaki "kaybolan gradyan" problemini "Skip Connections" ile Ã§Ã¶zerek gÃ¶rsel Ã¶zellikleri kaybetmeden derinlemesine analiz yapabilme.
Muhammed Ali CÃ¼re	MobileNetV2	DÃ¼ÅŸÃ¼k hesaplama maliyetiyle yÃ¼ksek verimlilik sunmasÄ±. Mobil veya gerÃ§ek zamanlÄ± sistemler iÃ§in hafif model ihtiyacÄ±nÄ± karÅŸÄ±lama potansiyeli.
ğŸ› ï¸ KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler
<p align="left">
<a href="https://www.python.org" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a>
<a href="https://www.tensorflow.org" target="_blank"> <img src="https://www.vectorlogo.zone/logos/tensorflow/tensorflow-icon.svg" alt="tensorflow" width="40" height="40"/> </a>
<a href="https://keras.io/" target="_blank"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Keras_logo.svg/1200px-Keras_logo.svg.png" alt="keras" width="40" height="40"/> </a>
<a href="https://scikit-learn.org/" target="_blank"> <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" alt="scikit_learn" width="40" height="40"/> </a>
<a href="https://opencv.org/" target="_blank"> <img src="https://www.vectorlogo.zone/logos/opencv/opencv-icon.svg" alt="opencv" width="40" height="40"/> </a>
<a href="https://pandas.pydata.org/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a>
<a href="https://numpy.org/" target="_blank"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/numpy/numpy-original.svg" alt="numpy" width="40" height="40"/> </a>
<a href="https://matplotlib.org/" target="_blank"> <img src="https://matplotlib.org/_static/logo_dark.svg" alt="matplotlib" width="40" height="40"/> </a>
<a href="https://colab.research.google.com/" target="_blank"> <img src="https://www.vectorlogo.zone/logos/google_colab/google_colab-icon.svg" alt="colab" width="40" height="40"/> </a>
</p>
ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma
Bu repoyu klonlayÄ±n:
code
Bash
git clone https://github.com/murat-khabibullayev/Deepfake-detection-project.git
Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin. Notebook'un en baÅŸÄ±ndaki !pip install komutlarÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmanÄ±z yeterlidir.
code
Bash
pip install tensorflow mtcnn scikit-learn pandas opencv-python matplotlib
Projeyi Deepfake_Detection.ipynb Jupyter Notebook dosyasÄ±nÄ± Google Colaboratory Ã¼zerinde aÃ§arak Ã§alÄ±ÅŸtÄ±rÄ±n. Veri setinin ve modelin kaydedileceÄŸi yollarÄ±n kendi Google Drive yapÄ±nÄ±zla uyumlu olduÄŸundan emin olun.
